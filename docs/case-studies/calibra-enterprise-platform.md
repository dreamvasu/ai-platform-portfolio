# Case Study: Calibra - Enterprise Calibration Management Platform

**Project Duration:** March 2024 - October 2024
**Role:** Lead Backend Architect & Platform Engineer
**Industry:** Scientific Instrumentation & Calibration Services
**Deployment:** Azure App Service (Production)

---

## Executive Summary

Calibra is a multi-tenant SaaS platform managing end-to-end calibration workflows for scientific instrumentation companies. The platform handles service request forms (SRFs), equipment observations, calibration certificates, and quotation management with complex scientific calculations and regulatory compliance requirements.

**Business Impact:**
- Processes 10,000+ calibration requests annually across multiple tenants
- Reduced calibration turnaround time by 40%
- Automated PDF report generation saving 200+ hours/month
- 99.9% uptime SLA with zero data loss

---

## Technical Architecture

### System Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        AZURE CLOUD                                â”‚
â”‚                                                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚               Azure App Service (Web Tier)                   â”‚â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚â”‚
â”‚  â”‚  â”‚  Django Application  â”‚  â”‚   Gunicorn Workers (4x)      â”‚â”‚â”œâ”€ Public HTTPS
â”‚  â”‚  â”‚  Multi-tenant Routingâ”‚  â”‚   Auto-scaling (2-10 inst)   â”‚â”‚â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                              â”‚                                   â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚
â”‚                    â”‚                  â”‚                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  PostgreSQL (Flexible  â”‚  â”‚  Redis Cache                   â”‚ â”‚
â”‚  â”‚  Server - Premium SSD) â”‚  â”‚  (Session store + job queue)   â”‚ â”‚
â”‚  â”‚  Multi-tenant schemas  â”‚  â”‚  6GB, High availability        â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                              â”‚                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚               Azure Blob Storage                             â”‚â”‚
â”‚  â”‚  - PDF Reports (~50GB)                                       â”‚â”‚
â”‚  â”‚  - Backup Archives (automated retention)                     â”‚â”‚
â”‚  â”‚  - Media files (equipment images)                            â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Multi-Tenancy Architecture

**Challenge:** Each client requires complete data isolation with custom branding, workflows, and domain mapping.

**Solution:** Implemented django-tenants with PostgreSQL schema-based isolation:

```python
# Architecture Pattern
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Shared Database (PostgreSQL)            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Schema: public        â”‚ Core tenant registry       â”‚
â”‚  Schema: client_acme   â”‚ Acme Corp's isolated data  â”‚
â”‚  Schema: client_techco â”‚ TechCo's isolated data     â”‚
â”‚  Schema: client_labx   â”‚ LabX's isolated data       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

# Tenant routing via subdomain/domain
acme.calibra.com       â†’ Routes to 'client_acme' schema
techco.calibra.com     â†’ Routes to 'client_techco' schema
custom-domain.com      â†’ Routes to mapped tenant
```

**Key Features:**
- **Zero cross-tenant data leakage** - Enforced at database connection level
- **Per-tenant customization** - Branding, workflows, pricing rules
- **Dynamic tenant provisioning** - New clients onboarded without deployment
- **Tenant-aware backups** - Isolated backup/restore per client

---

## Technical Challenges & Solutions

### Challenge 1: Complex State Management for Calibration Workflows

**Problem:**
Calibration requests go through 15+ states (Received â†’ Assigned â†’ In-Progress â†’ QC â†’ Approved â†’ Invoiced â†’ Delivered). Need full audit trail, state rollback, and concurrent modifications by multiple roles.

**Solution:** Event-sourced record-keeping system:

```python
class SRFRecords(models.Model):
    """Immutable point-in-time snapshots of SRF state"""
    parent_srf = models.ForeignKey(ServiceRequirement)
    object_json = models.JSONField()  # Complete serialized state
    srf_pdf = models.FileField()       # Generated PDF at this state
    created_date = models.DateTimeField(auto_now_add=True)
    created_by = models.ForeignKey(User)
    state_transition = models.CharField()  # Which action triggered this

    @property
    def is_record_updated(self):
        """Check if parent was modified after this snapshot"""
        return self.parent_srf.last_update < self.created_date
```

**Benefits:**
- Full audit trail with "who changed what when"
- Point-in-time recovery
- No data loss on concurrent updates
- Compliance with ISO 17025 calibration standards

### Challenge 2: High-Volume PDF Generation

**Problem:**
Generate 500+ calibration certificates daily with complex templates (graphs, tables, signatures, watermarks). Initial implementation took 30s per PDF, blocking requests.

**Solution:** Async PDF generation with caching:

```python
# Architecture
User Request â†’ API â†’ Celery Task â†’ Redis Queue â†’ Worker Pool â†’ Azure Blob
                â†“                                    â†“
         Return Job ID                          Generate PDF
                                                Store in Blob
                                                Cache metadata
```

**Optimizations:**
- **Template pre-compilation** - Reduced render time to 3-5s
- **Celery distributed workers** - 10 concurrent PDF generators
- **Result caching** - 95% hit rate for re-downloads
- **Progressive delivery** - Return job ID immediately, webhook on completion

**Metrics:**
- 30s â†’ 5s average generation time
- 500+ PDFs/day without blocking
- Zero timeout errors

### Challenge 3: Database Performance at Scale

**Problem:**
Complex queries with 15+ joins across tenant schemas causing 5-10s page loads. Observation data growing at 100K rows/month.

**Solution:** Query optimization + caching strategy:

```python
# Before: N+1 queries, no indexes
observations = Observation.objects.filter(srf__tenant=tenant)
for obs in observations:
    obs.equipment.name  # Separate query
    obs.technician.name  # Separate query
    obs.calibration_data  # Huge JSON fetch

# After: Optimized
observations = (
    Observation.objects
    .filter(srf__tenant=tenant)
    .select_related('equipment', 'technician', 'srf')  # JOIN once
    .prefetch_related('measurements')  # Batch fetch
    .only('id', 'date', 'status')  # Deferred columns
    .order_by('-created_date')
)
```

**Additional optimizations:**
- **Database indexes** - 20+ strategic indexes on foreign keys, date fields
- **Connection pooling** - PgBouncer reducing connection overhead
- **Query result caching** - Redis caching for read-heavy dashboard queries
- **Pagination** - Limit 50 results per API call

**Results:**
- 5-10s â†’ 200-400ms query time
- Database CPU usage dropped 60%
- Supports 1000+ concurrent users

### Challenge 4: Zero-Downtime Tenant Data Migrations

**Problem:**
Migrating 50GB+ of data across 20 tenants without downtime. Traditional `manage.py migrate` locks tables causing 10+ minute outages.

**Solution:** Blue-green migration strategy with tenant-specific rollout:

```python
class TenantMigrationOrchestrator:
    """Manages rolling tenant migrations"""

    def migrate_tenant_batch(self, tenants, migration):
        for tenant in tenants:
            # Switch to tenant schema
            connection.set_tenant(tenant)

            # Run migration in transaction
            with transaction.atomic():
                call_command('migrate', f'--schema={tenant.schema_name}')

            # Verify migration success
            if not self.validate_migration(tenant):
                self.rollback_tenant(tenant)
                raise MigrationFailed(f"Failed for {tenant}")

        # Only after all succeed, deploy new code
        self.deploy_new_version()
```

**Strategy:**
1. Migrate 2-3 tenants (lowest traffic)
2. Monitor for errors for 1 hour
3. If successful, migrate next batch
4. If errors, rollback and debug
5. New code only deployed after all migrations succeed

**Results:**
- Zero downtime for end users
- Failed migrations caught before full rollout
- Confidence in production changes

---

## DevOps & Platform Engineering

### CI/CD Pipeline

```yaml
# .gitlab-ci.yml
stages:
  - test
  - build
  - deploy-staging
  - deploy-production

test:
  stage: test
  script:
    - pytest --cov=. --cov-report=xml
    - pylint calibra/
  coverage: '/TOTAL.*\s+(\d+%)$/'

build:
  stage: build
  script:
    - docker build -t calibra:$CI_COMMIT_SHA .
    - docker push $REGISTRY/calibra:$CI_COMMIT_SHA

deploy-staging:
  stage: deploy-staging
  script:
    - az webapp config container set --name calibra-staging
          --image $REGISTRY/calibra:$CI_COMMIT_SHA
  environment:
    name: staging
    url: https://staging.calibra.com

deploy-production:
  stage: deploy-production
  when: manual  # Require approval
  script:
    - az webapp config container set --name calibra-prod
          --image $REGISTRY/calibra:$CI_COMMIT_SHA
  environment:
    name: production
    url: https://calibra.com
```

### Monitoring & Observability

**Azure Application Insights Integration:**
- Request/response times tracked per tenant
- Custom metrics for calibration processing time
- Alert rules for error rate spikes
- Distributed tracing across microservices

**Key Metrics Tracked:**
```python
# Custom telemetry
from applicationinsights import TelemetryClient

tc = TelemetryClient(settings.APPINSIGHTS_KEY)

# Track calibration processing time
with tc.track_time('calibration.observation.process'):
    result = process_observation(observation_id)

# Track tenant-specific metrics
tc.track_metric('tenant.active_users', count,
                properties={'tenant': tenant.name})
```

### Backup & Disaster Recovery

**Automated Backup Strategy:**
- **Database backups** - Azure PostgreSQL automated daily backups (35-day retention)
- **Blob storage replication** - GRS (Geo-Redundant Storage) across regions
- **Application-level exports** - Weekly full tenant data exports to archive storage

**Recovery Capabilities:**
```python
class TenantBackupService:
    """Tenant-isolated backup/restore"""

    def create_tenant_backup(self, tenant, date_range=None):
        """
        Exports complete tenant data:
        - All Records (JSON + PDFs)
        - User accounts & permissions
        - Configuration & branding
        - Audit logs
        """
        backup_structure = {
            'metadata': self._generate_metadata(tenant),
            'srfs': self._export_srf_records(tenant, date_range),
            'observations': self._export_observations(tenant, date_range),
            'certificates': self._export_certificates(tenant, date_range),
            'users': self._export_users(tenant),
        }

        # Compress and upload to Azure Blob
        archive_path = self._create_archive(backup_structure)
        self._upload_to_blob(archive_path, tenant)

    def restore_tenant(self, tenant, backup_date):
        """Point-in-time tenant restore"""
        # Download archive from Blob
        # Create new schema
        # Import data
        # Validate integrity
```

**RTO/RPO:**
- **Recovery Time Objective:** < 4 hours for full tenant restore
- **Recovery Point Objective:** < 1 hour (transaction log backups every 15 min)

---

## Infrastructure as Code

### Azure Resource Provisioning

```hcl
# Terraform configuration for Calibra infrastructure
resource "azurerm_app_service_plan" "calibra" {
  name                = "calibra-plan"
  location            = "East US"
  kind                = "Linux"
  reserved            = true

  sku {
    tier = "PremiumV2"
    size = "P2v2"  # 2 cores, 7GB RAM
    capacity = 2    # Min instances
  }
}

resource "azurerm_app_service" "calibra_web" {
  name                = "calibra-prod"
  app_service_plan_id = azurerm_app_service_plan.calibra.id

  app_settings = {
    "DJANGO_SETTINGS_MODULE" = "calibra.settings.production"
    "DATABASE_URL" = azurerm_postgresql_flexible_server.calibra.connection_string
    "REDIS_URL" = azurerm_redis_cache.calibra.primary_connection_string
  }

  connection_string {
    name  = "PostgreSQL"
    type  = "PostgreSQL"
    value = azurerm_postgresql_flexible_server.calibra.connection_string
  }

  site_config {
    linux_fx_version = "DOCKER|calibra:latest"
    always_on        = true
    health_check_path = "/api/health/"

    auto_heal_enabled = true
    auto_heal {
      triggers {
        slow_request {
          time_taken = "00:01:00"
          count      = 5
        }
      }
      actions {
        action_type = "Recycle"
      }
    }
  }
}

resource "azurerm_postgresql_flexible_server" "calibra" {
  name                = "calibra-postgres"
  sku_name            = "GP_Standard_D4s_v3"  # 4 vCores, 16GB RAM
  storage_mb          = 524288  # 512GB SSD
  backup_retention_days = 35
  geo_redundant_backup_enabled = true

  high_availability {
    mode = "ZoneRedundant"  # Failover in <1 min
  }
}
```

---

## Production Deployment Walkthrough

### Prerequisites

Before deploying Calibra to Azure, ensure you have:

```bash
# Required tools
az --version          # Azure CLI 2.50+
docker --version      # Docker 24+
python3 --version     # Python 3.11+
terraform --version   # Terraform 1.5+

# Azure login
az login
az account set --subscription "Your-Subscription-Name"

# Set environment variables
export RESOURCE_GROUP="calibra-prod-rg"
export LOCATION="eastus"
export APP_NAME="calibra-prod"
```

### Step 1: Create Azure Resources

```bash
# 1.1 Create Resource Group
az group create \
  --name $RESOURCE_GROUP \
  --location $LOCATION

# 1.2 Create App Service Plan (Premium v2)
az appservice plan create \
  --name calibra-plan \
  --resource-group $RESOURCE_GROUP \
  --is-linux \
  --sku P2V2 \
  --number-of-workers 2

# 1.3 Create PostgreSQL Flexible Server
az postgres flexible-server create \
  --name calibra-postgres \
  --resource-group $RESOURCE_GROUP \
  --location $LOCATION \
  --admin-user calibraadmin \
  --admin-password 'YOUR_STRONG_PASSWORD' \
  --sku-name Standard_D4s_v3 \
  --tier GeneralPurpose \
  --storage-size 512 \
  --backup-retention 35 \
  --high-availability ZoneRedundant \
  --version 15

# 1.4 Configure PostgreSQL firewall
az postgres flexible-server firewall-rule create \
  --resource-group $RESOURCE_GROUP \
  --name calibra-postgres \
  --rule-name AllowAzureServices \
  --start-ip-address 0.0.0.0 \
  --end-ip-address 0.0.0.0

# 1.5 Create Redis Cache
az redis create \
  --name calibra-redis \
  --resource-group $RESOURCE_GROUP \
  --location $LOCATION \
  --sku Premium \
  --vm-size P1 \
  --redis-configuration '{"maxmemory-policy":"allkeys-lru"}' \
  --enable-non-ssl-port false

# 1.6 Create Blob Storage Account
az storage account create \
  --name calibrablobstorage \
  --resource-group $RESOURCE_GROUP \
  --location $LOCATION \
  --sku Standard_GRS \
  --kind StorageV2 \
  --access-tier Hot

# Create container for PDFs
az storage container create \
  --name calibration-pdfs \
  --account-name calibrablobstorage \
  --public-access off
```

### Step 2: Build and Push Docker Image

```bash
# 2.1 Create Azure Container Registry (ACR)
az acr create \
  --resource-group $RESOURCE_GROUP \
  --name calibraregistry \
  --sku Standard

# 2.2 Login to ACR
az acr login --name calibraregistry

# 2.3 Build multi-stage Docker image
docker build -t calibra:v1.0.0 -f Dockerfile.production .

# 2.4 Tag and push
docker tag calibra:v1.0.0 calibraregistry.azurecr.io/calibra:v1.0.0
docker push calibraregistry.azurecr.io/calibra:v1.0.0
```

### Step 3: Create Web App with Container

```bash
# 3.1 Create App Service
az webapp create \
  --resource-group $RESOURCE_GROUP \
  --plan calibra-plan \
  --name $APP_NAME \
  --deployment-container-image-name calibraregistry.azurecr.io/calibra:v1.0.0

# 3.2 Configure ACR authentication
ACR_PASSWORD=$(az acr credential show \
  --name calibraregistry \
  --query passwords[0].value \
  --output tsv)

az webapp config container set \
  --name $APP_NAME \
  --resource-group $RESOURCE_GROUP \
  --docker-custom-image-name calibraregistry.azurecr.io/calibra:v1.0.0 \
  --docker-registry-server-url https://calibraregistry.azurecr.io \
  --docker-registry-server-user calibraregistry \
  --docker-registry-server-password $ACR_PASSWORD

# 3.3 Configure continuous deployment
az webapp deployment container config \
  --name $APP_NAME \
  --resource-group $RESOURCE_GROUP \
  --enable-cd true
```

### Step 4: Configure Environment Variables

```bash
# Get connection strings
POSTGRES_CONN=$(az postgres flexible-server show-connection-string \
  --server-name calibra-postgres \
  --database-name calibra_prod \
  --admin-user calibraadmin \
  --admin-password 'YOUR_PASSWORD' \
  --query connectionStrings.django \
  --output tsv)

REDIS_KEY=$(az redis list-keys \
  --name calibra-redis \
  --resource-group $RESOURCE_GROUP \
  --query primaryKey \
  --output tsv)

BLOB_CONN=$(az storage account show-connection-string \
  --name calibrablobstorage \
  --resource-group $RESOURCE_GROUP \
  --query connectionString \
  --output tsv)

# Set app settings
az webapp config appsettings set \
  --name $APP_NAME \
  --resource-group $RESOURCE_GROUP \
  --settings \
    DJANGO_SETTINGS_MODULE="calibra.settings.production" \
    SECRET_KEY="$(openssl rand -base64 48)" \
    DATABASE_URL="$POSTGRES_CONN" \
    REDIS_URL="rediss://calibra-redis.redis.cache.windows.net:6380?password=$REDIS_KEY&ssl_cert_reqs=required" \
    AZURE_STORAGE_CONNECTION_STRING="$BLOB_CONN" \
    ALLOWED_HOSTS="$APP_NAME.azurewebsites.net,calibra.com,*.calibra.com" \
    DEBUG="False" \
    ENABLE_MULTI_TENANT="True"
```

### Step 5: Database Setup and Migrations

```bash
# 5.1 SSH into app container
az webapp ssh --name $APP_NAME --resource-group $RESOURCE_GROUP

# 5.2 Inside container - create databases
python manage.py shell <<EOF
from django.db import connection
from django_tenants.utils import schema_context

# Create public schema tables
connection.cursor().execute("CREATE EXTENSION IF NOT EXISTS pg_trgm;")
EOF

# 5.3 Run migrations for public schema
python manage.py migrate_schemas --shared

# 5.4 Create first tenant
python manage.py create_tenant \
  --schema_name=client_acme \
  --name="Acme Corporation" \
  --domain=acme.calibra.com \
  --is_primary=true

# 5.5 Run tenant migrations
python manage.py migrate_schemas --tenant

# Exit SSH
exit
```

### Step 6: Configure Custom Domains

```bash
# 6.1 Add custom domain
az webapp config hostname add \
  --webapp-name $APP_NAME \
  --resource-group $RESOURCE_GROUP \
  --hostname calibra.com

# 6.2 Enable HTTPS with managed certificate
az webapp config ssl create \
  --name $APP_NAME \
  --resource-group $RESOURCE_GROUP \
  --hostname calibra.com

az webapp config ssl bind \
  --name $APP_NAME \
  --resource-group $RESOURCE_GROUP \
  --certificate-thumbprint <THUMBPRINT> \
  --ssl-type SNI
```

### Step 7: Enable Auto-scaling

```bash
# Create autoscale rule
az monitor autoscale create \
  --resource-group $RESOURCE_GROUP \
  --name calibra-autoscale \
  --resource $APP_NAME \
  --resource-type "Microsoft.Web/serverfarms" \
  --min-count 2 \
  --max-count 10 \
  --count 2

# Scale up on CPU > 75%
az monitor autoscale rule create \
  --resource-group $RESOURCE_GROUP \
  --autoscale-name calibra-autoscale \
  --condition "Percentage CPU > 75 avg 5m" \
  --scale out 2

# Scale down on CPU < 30%
az monitor autoscale rule create \
  --resource-group $RESOURCE_GROUP \
  --autoscale-name calibra-autoscale \
  --condition "Percentage CPU < 30 avg 10m" \
  --scale in 1
```

### Step 8: Deploy Celery Workers

```bash
# 8.1 Create separate App Service for workers
az webapp create \
  --resource-group $RESOURCE_GROUP \
  --plan calibra-plan \
  --name calibra-celery-workers \
  --deployment-container-image-name calibraregistry.azurecr.io/calibra:v1.0.0

# 8.2 Override startup command for Celery
az webapp config set \
  --name calibra-celery-workers \
  --resource-group $RESOURCE_GROUP \
  --startup-file "celery -A calibra worker -l info -c 4"

# 8.3 Create Beat scheduler
az webapp create \
  --resource-group $RESOURCE_GROUP \
  --plan calibra-plan \
  --name calibra-celery-beat \
  --deployment-container-image-name calibraregistry.azurecr.io/calibra:v1.0.0

az webapp config set \
  --name calibra-celery-beat \
  --resource-group $RESOURCE_GROUP \
  --startup-file "celery -A calibra beat -l info"
```

### Step 9: Configure Monitoring

```bash
# 9.1 Create Application Insights
az monitor app-insights component create \
  --app calibra-insights \
  --location $LOCATION \
  --resource-group $RESOURCE_GROUP \
  --application-type web

# 9.2 Get instrumentation key
INSIGHTS_KEY=$(az monitor app-insights component show \
  --app calibra-insights \
  --resource-group $RESOURCE_GROUP \
  --query instrumentationKey \
  --output tsv)

# 9.3 Add to app settings
az webapp config appsettings set \
  --name $APP_NAME \
  --resource-group $RESOURCE_GROUP \
  --settings APPINSIGHTS_INSTRUMENTATIONKEY="$INSIGHTS_KEY"

# 9.4 Enable diagnostic logging
az webapp log config \
  --name $APP_NAME \
  --resource-group $RESOURCE_GROUP \
  --application-logging true \
  --detailed-error-messages true \
  --failed-request-tracing true \
  --web-server-logging filesystem
```

### Step 10: Verification

```bash
# 10.1 Check app is running
az webapp browse --name $APP_NAME --resource-group $RESOURCE_GROUP

# 10.2 Test health endpoint
curl https://$APP_NAME.azurewebsites.net/api/health/
# Expected: {"status": "healthy", "database": "connected", "redis": "connected"}

# 10.3 Test tenant routing
curl -H "Host: acme.calibra.com" https://$APP_NAME.azurewebsites.net/api/tenant-info/
# Expected: {"tenant": "client_acme", "name": "Acme Corporation"}

# 10.4 Check logs
az webapp log tail --name $APP_NAME --resource-group $RESOURCE_GROUP

# 10.5 Verify autoscaling
az monitor autoscale show \
  --resource-group $RESOURCE_GROUP \
  --name calibra-autoscale
```

### Deployment Checklist

- [ ] All Azure resources created (App Service, PostgreSQL, Redis, Blob Storage)
- [ ] Docker image built and pushed to ACR
- [ ] Environment variables configured correctly
- [ ] Database migrations completed for public schema
- [ ] At least one tenant created and migrated
- [ ] Custom domains configured with SSL
- [ ] Auto-scaling rules enabled
- [ ] Celery workers and beat scheduler deployed
- [ ] Application Insights configured
- [ ] Health checks passing
- [ ] Logs streaming successfully
- [ ] Backup strategy verified

---

## Verification & Testing

### Test Scenario 1: Multi-Tenant Routing

```bash
# Test tenant isolation
curl -H "Host: acme.calibra.com" https://calibra-prod.azurewebsites.net/api/srfs/ \
  -H "Authorization: Bearer YOUR_TOKEN"
# Should return only Acme's SRFs

curl -H "Host: techco.calibra.com" https://calibra-prod.azurewebsites.net/api/srfs/ \
  -H "Authorization: Bearer YOUR_TOKEN"
# Should return only TechCo's SRFs
```

### Test Scenario 2: PDF Generation

```bash
# Trigger async PDF generation
curl -X POST https://calibra-prod.azurewebsites.net/api/srfs/12345/generate-certificate/ \
  -H "Authorization: Bearer YOUR_TOKEN" \
  -H "Content-Type: application/json"

# Response: {"job_id": "abc-123-def", "status": "processing"}

# Check job status
curl https://calibra-prod.azurewebsites.net/api/jobs/abc-123-def/ \
  -H "Authorization: Bearer YOUR_TOKEN"

# Response: {"status": "completed", "pdf_url": "https://calibrablobstorage.blob.core.windows.net/..."}
```

### Test Scenario 3: Load Testing

```bash
# Install Apache Bench
apt-get install apache2-utils

# Test API endpoint
ab -n 1000 -c 50 \
  -H "Authorization: Bearer YOUR_TOKEN" \
  https://calibra-prod.azurewebsites.net/api/srfs/

# Expected Results:
# Requests per second: 150-250
# Time per request (mean): 200-400ms
# Failed requests: 0
```

### Test Scenario 4: Database Query Performance

```python
# Django shell
python manage.py tenant_command shell

# Test N+1 query optimization
from django.db import connection, reset_queries
from calibra.models import ServiceRequirement

reset_queries()
srfs = ServiceRequirement.objects.all()[:100]
for srf in srfs:
    _ = srf.equipment.name  # Should not trigger new query
    _ = srf.technician.name  # Should not trigger new query

print(f"Total queries: {len(connection.queries)}")
# Expected: 3-5 queries (not 200+)
```

### Test Scenario 5: Event Sourcing Audit Trail

```bash
# Check SRF history
curl https://calibra-prod.azurewebsites.net/api/srfs/12345/history/ \
  -H "Authorization: Bearer YOUR_TOKEN"

# Response should show all state transitions:
# [
#   {"state": "created", "user": "john@acme.com", "timestamp": "2024-10-01T10:00:00Z"},
#   {"state": "assigned", "user": "tech@acme.com", "timestamp": "2024-10-01T11:30:00Z"},
#   {"state": "completed", "user": "tech@acme.com", "timestamp": "2024-10-02T14:00:00Z"}
# ]
```

### Test Scenario 6: Disaster Recovery

```bash
# Create tenant backup
python manage.py backup_tenant --tenant=client_acme --output=/tmp/acme_backup.tar.gz

# Simulate data loss (staging only!)
python manage.py shell
>>> from django_tenants.utils import tenant_context, get_tenant_model
>>> tenant = get_tenant_model().objects.get(schema_name='client_acme_test')
>>> with tenant_context(tenant):
>>>     ServiceRequirement.objects.all().delete()

# Restore from backup
python manage.py restore_tenant --tenant=client_acme_test --backup=/tmp/acme_backup.tar.gz

# Verify restoration
python manage.py tenant_command shell --schema=client_acme_test
>>> ServiceRequirement.objects.count()
# Should match pre-deletion count
```

---

## Security & Compliance

### Authentication & Authorization

- **JWT-based API authentication** - 3-hour access tokens with refresh
- **Role-based access control** - 12 permission levels (Admin, Manager, Technician, Viewer, etc.)
- **Per-tenant user isolation** - Users can't access other tenants' data
- **API rate limiting** - 1000 requests/hour per user, 10000/hour per tenant

### Data Protection

- **Encryption at rest** - Azure Blob Storage SSE, PostgreSQL TDE
- **Encryption in transit** - TLS 1.2+ enforced
- **PII data handling** - Customer contact info encrypted with tenant-specific keys
- **GDPR compliance** - Right to erasure, data portability, audit logs

### Compliance Standards

- **ISO 17025** - Calibration laboratory quality management
- **21 CFR Part 11** - FDA electronic records compliance (for pharma clients)
- **Audit logging** - All data modifications logged with user, timestamp, before/after values

---

## Troubleshooting Guide

### Issue 1: Tenant Routing Not Working

**Symptoms:**
- Getting 404 errors when accessing tenant subdomains
- Wrong tenant data displayed
- "Tenant matching query does not exist" errors

**Diagnosis:**
```bash
# Check tenant middleware configuration
az webapp log tail --name calibra-prod --resource-group calibra-prod-rg | grep "TenantMiddleware"

# Verify tenant exists in database
az webapp ssh --name calibra-prod --resource-group calibra-prod-rg
python manage.py shell
>>> from django_tenants.utils import get_tenant_model
>>> get_tenant_model().objects.all()
>>> # Check if domain is correctly configured
>>> tenant = get_tenant_model().objects.get(schema_name='client_acme')
>>> tenant.domains.all()
```

**Solution:**
```python
# Fix 1: Ensure TenantMiddleware is first in MIDDLEWARE
# settings.py
MIDDLEWARE = [
    'django_tenants.middleware.main.TenantMainMiddleware',  # MUST be first
    'django.middleware.security.SecurityMiddleware',
    # ... rest
]

# Fix 2: Create missing domain mapping
python manage.py shell
>>> from django_tenants.utils import get_tenant_model, get_tenant_domain_model
>>> tenant = get_tenant_model().objects.get(schema_name='client_acme')
>>> Domain = get_tenant_domain_model()
>>> Domain.objects.create(domain='acme.calibra.com', tenant=tenant, is_primary=True)

# Fix 3: Clear tenant cache
>>> from django.core.cache import cache
>>> cache.clear()
```

### Issue 2: Cross-Tenant Data Leakage

**Symptoms:**
- User sees data from different tenant
- Queries returning data from wrong schema
- Security audit failing

**Diagnosis:**
```python
# Check current schema context
from django.db import connection
print(f"Current schema: {connection.schema_name}")

# Verify query is hitting correct schema
from calibra.models import ServiceRequirement
from django.db import connection, reset_queries

reset_queries()
srfs = ServiceRequirement.objects.all()
print(connection.queries)
# Look for: SET search_path TO "client_acme"
```

**Solution:**
```python
# Fix 1: Always use tenant_context for manual queries
from django_tenants.utils import tenant_context, get_tenant_model

tenant = get_tenant_model().objects.get(schema_name='client_acme')
with tenant_context(tenant):
    # All queries here are isolated to client_acme schema
    srfs = ServiceRequirement.objects.all()

# Fix 2: Add schema validation decorator
def ensure_tenant_context(func):
    """Decorator to ensure tenant is set"""
    def wrapper(*args, **kwargs):
        from django.db import connection
        if not hasattr(connection, 'tenant') or connection.tenant is None:
            raise ValueError("No tenant context set!")
        return func(*args, **kwargs)
    return wrapper

# Fix 3: Add database-level constraint (PostgreSQL)
ALTER TABLE calibra_servicerequirement
ADD CONSTRAINT check_schema
CHECK (pg_catalog.current_schema() = 'client_acme' OR pg_catalog.current_schema() = 'client_techco');
```

### Issue 3: Migration Failures Across Tenants

**Symptoms:**
- Migration works for some tenants, fails for others
- "relation already exists" errors
- "column does not exist" errors mid-rollout

**Diagnosis:**
```bash
# Check migration status per tenant
python manage.py showmigrations --schema=client_acme
python manage.py showmigrations --schema=client_techco

# Identify which tenant failed
az webapp log tail --name calibra-prod --resource-group calibra-prod-rg | grep "MigrationFailed"
```

**Solution:**
```bash
# Fix 1: Run migrations one tenant at a time
python manage.py migrate_schemas --schema=client_acme
# Verify success before continuing
python manage.py migrate_schemas --schema=client_techco

# Fix 2: Rollback failed tenant migration
python manage.py migrate calibra 0015_previous_migration --schema=client_acme

# Fix 3: Use idempotent migrations
# migrations/0016_add_column.py
from django.db import migrations, models

class Migration(migrations.Migration):
    operations = [
        migrations.RunSQL(
            sql="""
            DO $$
            BEGIN
                IF NOT EXISTS (
                    SELECT 1 FROM information_schema.columns
                    WHERE table_name='servicerequirement' AND column_name='new_field'
                ) THEN
                    ALTER TABLE servicerequirement ADD COLUMN new_field VARCHAR(255);
                END IF;
            END $$;
            """,
            reverse_sql="ALTER TABLE servicerequirement DROP COLUMN IF EXISTS new_field;"
        )
    ]

# Fix 4: Emergency repair - clone schema from working tenant
pg_dump -h calibra-postgres.postgres.database.azure.com \
    -U calibraadmin \
    --schema=client_techco \
    -Fc -f /tmp/client_techco_schema.dump

pg_restore -h calibra-postgres.postgres.database.azure.com \
    -U calibraadmin \
    -d calibra_prod \
    --schema=client_acme \
    --clean --if-exists \
    /tmp/client_techco_schema.dump
```

### Issue 4: PDF Generation Timeouts

**Symptoms:**
- 500 errors when requesting calibration certificates
- Celery workers showing "SoftTimeLimitExceeded"
- Azure App Service timing out after 230s

**Diagnosis:**
```bash
# Check Celery worker logs
az webapp log tail --name calibra-celery-workers --resource-group calibra-prod-rg

# Check task queue backlog
python manage.py shell
>>> from celery import Celery
>>> app = Celery('calibra')
>>> inspect = app.control.inspect()
>>> inspect.active()  # Currently processing
>>> inspect.reserved()  # Queued tasks

# Check Blob storage performance
az monitor metrics list \
    --resource calibrablobstorage \
    --metric SuccessE2ELatency \
    --resource-group calibra-prod-rg
```

**Solution:**
```python
# Fix 1: Increase Celery timeout
# celery.py
app.conf.task_soft_time_limit = 600  # 10 minutes
app.conf.task_time_limit = 900  # 15 minutes hard limit

# Fix 2: Optimize PDF generation
from django.core.cache import cache

def generate_certificate_pdf(srf_id):
    # Check cache first
    cache_key = f"pdf_certificate_{srf_id}"
    cached_pdf = cache.get(cache_key)
    if cached_pdf:
        return cached_pdf

    # Pre-fetch all related data in one query
    srf = (ServiceRequirement.objects
           .select_related('equipment', 'customer', 'technician')
           .prefetch_related('observations__measurements')
           .get(id=srf_id))

    # Use optimized template rendering
    template = get_template('certificate.html')
    html = template.render({'srf': srf})

    # Generate PDF with timeout
    pdf = generate_pdf(html, timeout=30)

    # Cache for 1 hour
    cache.set(cache_key, pdf, 3600)
    return pdf

# Fix 3: Scale Celery workers
az webapp scale --name calibra-celery-workers \
    --resource-group calibra-prod-rg \
    --number-of-workers 5

# Fix 4: Add task priority queue
# celery.py
app.conf.task_routes = {
    'calibra.tasks.generate_certificate': {'queue': 'high_priority'},
    'calibra.tasks.send_email': {'queue': 'low_priority'},
}
```

### Issue 5: Database Connection Pool Exhausted

**Symptoms:**
- "FATAL: remaining connection slots are reserved" errors
- Intermittent 500 errors under load
- Slow response times during peak hours

**Diagnosis:**
```sql
-- Check current connections
SELECT count(*) FROM pg_stat_activity;

-- Check connections per database
SELECT datname, count(*)
FROM pg_stat_activity
GROUP BY datname;

-- Check idle connections
SELECT count(*)
FROM pg_stat_activity
WHERE state = 'idle' AND state_change < now() - interval '5 minutes';
```

**Solution:**
```python
# Fix 1: Configure connection pooling in Django
# settings.py
DATABASES = {
    'default': {
        'ENGINE': 'django_tenants.postgresql_backend',
        'CONN_MAX_AGE': 600,  # Reuse connections for 10 minutes
        'OPTIONS': {
            'connect_timeout': 10,
            'options': '-c statement_timeout=30000'
        },
    }
}

# Fix 2: Use PgBouncer (connection pooler)
# Add to Azure PostgreSQL via Azure CLI
az postgres flexible-server parameter set \
    --resource-group calibra-prod-rg \
    --server-name calibra-postgres \
    --name max_connections \
    --value 200

# Fix 3: Close idle connections
# management/commands/close_idle_connections.py
from django.core.management.base import BaseCommand
from django.db import connection

class Command(BaseCommand):
    def handle(self, *args, **options):
        with connection.cursor() as cursor:
            cursor.execute("""
                SELECT pg_terminate_backend(pid)
                FROM pg_stat_activity
                WHERE datname = 'calibra_prod'
                  AND state = 'idle'
                  AND state_change < now() - interval '10 minutes'
                  AND pid <> pg_backend_pid()
            """)

# Run as scheduled Celery task
from celery import shared_task

@shared_task
def cleanup_idle_connections():
    call_command('close_idle_connections')
```

### Issue 6: Multi-Tenant Backup Restoration Errors

**Symptoms:**
- Restore fails with "schema already exists"
- Foreign key constraint violations during restore
- Incomplete data after restoration

**Diagnosis:**
```bash
# Check existing schema
psql -h calibra-postgres.postgres.database.azure.com \
    -U calibraadmin \
    -d calibra_prod \
    -c "\dn"

# Verify backup file integrity
tar -tzf /tmp/client_acme_backup.tar.gz

# Check for constraint violations
psql -h calibra-postgres.postgres.database.azure.com \
    -U calibraadmin \
    -d calibra_prod \
    -c "SET search_path TO client_acme; SELECT * FROM information_schema.table_constraints WHERE constraint_type='FOREIGN KEY';"
```

**Solution:**
```bash
# Fix 1: Drop and recreate schema for clean restore
psql -h calibra-postgres.postgres.database.azure.com \
    -U calibraadmin \
    -d calibra_prod <<EOF
DROP SCHEMA IF EXISTS client_acme CASCADE;
CREATE SCHEMA client_acme;
EOF

# Fix 2: Restore with transaction rollback on error
pg_restore -h calibra-postgres.postgres.database.azure.com \
    -U calibraadmin \
    -d calibra_prod \
    --schema=client_acme \
    --single-transaction \
    --exit-on-error \
    /tmp/client_acme_backup.dump

# Fix 3: Handle constraint violations
# Disable foreign key checks during restore
psql -h calibra-postgres.postgres.database.azure.com \
    -U calibraadmin \
    -d calibra_prod <<EOF
SET search_path TO client_acme;
SET session_replication_role = 'replica';  -- Disable triggers/constraints
-- Run restore here
SET session_replication_role = 'origin';  -- Re-enable
EOF

# Fix 4: Verify restoration with data integrity checks
python manage.py shell
>>> from django_tenants.utils import tenant_context, get_tenant_model
>>> tenant = get_tenant_model().objects.get(schema_name='client_acme')
>>> with tenant_context(tenant):
>>>     from calibra.models import ServiceRequirement, Observation
>>>     srf_count = ServiceRequirement.objects.count()
>>>     obs_count = Observation.objects.count()
>>>     print(f"Restored: {srf_count} SRFs, {obs_count} observations")
>>>     # Verify foreign keys
>>>     orphaned = Observation.objects.filter(srf__isnull=True).count()
>>>     print(f"Orphaned observations: {orphaned}")  # Should be 0
```

### Common Error Messages & Quick Fixes

| Error | Quick Fix |
|-------|-----------|
| `TenantNotFound: No tenant found` | Check domain mapping, clear cache |
| `relation "client_x.table" does not exist` | Run `migrate_schemas --schema=client_x` |
| `FATAL: remaining connection slots reserved` | Increase `max_connections` or add PgBouncer |
| `Celery: SoftTimeLimitExceeded` | Increase `task_soft_time_limit` |
| `PDF generation timeout` | Optimize queries, add caching, scale workers |
| `Cross-tenant data leak detected` | Review middleware order, add schema checks |

---

## Technical Metrics

### Performance

| Metric | Value |
|--------|-------|
| API Response Time (p50) | 120ms |
| API Response Time (p95) | 450ms |
| PDF Generation Time | 3-5s |
| Database Query Time (avg) | 35ms |
| Concurrent Users Supported | 1000+ |
| Daily API Requests | 500K+ |
| Uptime (6 months) | 99.94% |

### Scale

| Metric | Value |
|--------|-------|
| Active Tenants | 20 |
| Total Users | 800+ |
| SRFs Processed/Year | 10,000+ |
| Database Size | 85GB |
| Blob Storage (PDFs) | 50GB |
| Daily Backups | 3GB compressed |

### Code Quality

| Metric | Value |
|--------|-------|
| Test Coverage | 87% |
| Lines of Code | 45,000+ |
| API Endpoints | 120+ |
| Database Tables | 80+ |
| Celery Tasks | 25 |

---

## Azure Cost Analysis & Optimization

### Monthly Cost Breakdown (Production)

#### Current Production Costs

| Resource | SKU/Tier | Quantity | Unit Cost | Monthly Cost |
|----------|----------|----------|-----------|--------------|
| **App Service Plan** | Premium V2 (P2v2) | 1 plan | $147.00 | $147.00 |
| **App Service Instances** | Auto-scale (2-10) | 2 avg | included | - |
| **PostgreSQL Flexible Server** | Standard_D4s_v3 | 1 server | $265.00 | $265.00 |
| **PostgreSQL Storage** | Premium SSD 512GB | 512 GB | $0.20/GB | $102.40 |
| **PostgreSQL Backup** | 35-day retention | ~100 GB | $0.095/GB | $9.50 |
| **Redis Cache** | Premium P1 (6GB) | 1 instance | $132.48 | $132.48 |
| **Blob Storage (Hot)** | Standard GRS | 50 GB | $0.024/GB | $1.20 |
| **Blob Transactions** | Write/Read ops | 1M ops | $0.065/10K | $6.50 |
| **Bandwidth (Egress)** | Data transfer out | 100 GB | $0.087/GB | $8.70 |
| **Application Insights** | Pay-as-you-go | 5 GB/day | $2.88/GB | $431.00 |
| **Azure Container Registry** | Standard | 1 registry | $20.00 | $20.00 |
| **Virtual Network** | Vnet + Peering | 1 vnet | $15.00 | $15.00 |
| **Load Balancer** | Basic | 1 LB | $18.26 | $18.26 |
| | | | **TOTAL** | **$1,157.04** |

### Cost Optimization Strategies

#### Implemented Optimizations

**1. App Service Auto-scaling**
```bash
# Current configuration
Min instances: 2
Max instances: 10
Average instances: 3-4 during business hours

# Cost impact
Without auto-scaling: 10 instances 24/7 = $735/month
With auto-scaling: 3.5 avg instances = $0/month (included in plan)
Savings: Effective use of resources
```

**2. PostgreSQL Reserved Capacity**
```bash
# Purchase 1-year reservation for PostgreSQL
az postgres flexible-server reserved-capacity create \
    --resource-group calibra-prod-rg \
    --reservation-name calibra-postgres-reserved \
    --sku-name Standard_D4s_v3 \
    --term P1Y

# Cost impact
Pay-as-you-go: $265/month = $3,180/year
1-year reserved: $2,100/year ($175/month)
Savings: $1,080/year (34% discount)
```

**3. Application Insights Sampling**
```python
# settings.py - Reduce telemetry volume
APPLICATIONINSIGHTS_CONFIG = {
    'adaptive_sampling_enabled': True,
    'sampling_percentage': 20.0,  # Sample 20% of requests
    'excluded_types': 'Request;Exception',  # Never sample errors
}

# Cost impact
Full telemetry: 5 GB/day = 150 GB/month = $431/month
20% sampling: 1 GB/day = 30 GB/month = $86/month
Savings: $345/month
```

**4. Blob Storage Lifecycle Management**
```bash
# Move old PDFs to Cool tier after 90 days
az storage account management-policy create \
    --account-name calibrablobstorage \
    --policy @policy.json

# policy.json
{
  "rules": [
    {
      "name": "MoveToCool",
      "type": "Lifecycle",
      "definition": {
        "actions": {
          "baseBlob": {
            "tierToCool": {"daysAfterModificationGreaterThan": 90},
            "tierToArchive": {"daysAfterModificationGreaterThan": 365}
          }
        }
      }
    }
  ]
}

# Cost impact
Hot: $0.024/GB * 50GB = $1.20/month
Cool (after 90 days): $0.012/GB * 40GB = $0.48/month
Savings: $0.72/month (grows as data accumulates)
```

**5. Redis Cache Optimization**
```python
# Implement cache warming and key expiration
from django.core.cache import cache

# Set aggressive TTLs
cache.set('dashboard_data', data, timeout=300)  # 5 minutes
cache.set('static_config', config, timeout=86400)  # 24 hours

# Use cache for read-heavy queries
def get_tenant_stats(tenant_id):
    cache_key = f'tenant_stats_{tenant_id}'
    stats = cache.get(cache_key)
    if not stats:
        stats = calculate_tenant_stats(tenant_id)
        cache.set(cache_key, stats, timeout=600)
    return stats

# Result: Can potentially downgrade to C3 (1GB) cache
# Premium P1 (6GB): $132/month
# Premium C3 (1GB): $75/month
# Potential savings: $57/month
```

#### Recommended Future Optimizations

**Option 1: Move to Azure Kubernetes Service (AKS)**

Estimated monthly cost:
```
AKS Cluster (3 nodes, Standard_D2s_v3): $220
Managed PostgreSQL (same): $265
Redis Cache (same): $132
Storage & Networking: $50
Application Insights (optimized): $86
Total: ~$753/month

Savings: $404/month (35% reduction)
Benefits: Better resource utilization, autoscaling, multi-region
```

**Option 2: Use Azure Database for PostgreSQL - Burstable tier**

For non-critical tenants or dev/staging:
```bash
# Burstable B2s instead of Standard_D4s_v3
Current: Standard_D4s_v3 = $265/month
Burstable: B2s (2 vCores) = $62/month

Savings for staging: $203/month
```

**Option 3: Implement CDN for Static/Media Files**

```bash
az cdn profile create \
    --name calibra-cdn \
    --resource-group calibra-prod-rg \
    --sku Standard_Microsoft

# Cost impact
CDN: $0.081/GB + $0.0075/10K requests = ~$15/month
Reduced egress from Blob: Save $6/month
Better performance: Priceless
Net cost: +$9/month (but improved UX)
```

### Cost Optimization Summary

| Optimization | Status | Monthly Savings | Annual Savings |
|--------------|--------|-----------------|----------------|
| PostgreSQL Reserved Capacity | âœ… Implemented | $90 | $1,080 |
| Application Insights Sampling | âœ… Implemented | $345 | $4,140 |
| Blob Lifecycle Management | âœ… Implemented | $1 (growing) | $12+ |
| Auto-scaling (vs fixed 10) | âœ… Implemented | Included | - |
| Redis Downgrade (C3) | ğŸ”„ Planned | $57 | $684 |
| AKS Migration | ğŸ“‹ Future | $404 | $4,848 |
| **TOTAL CURRENT SAVINGS** | | **$436/month** | **$5,232/year** |
| **TOTAL POTENTIAL SAVINGS** | | **$897/month** | **$10,764/year** |

### Optimized Monthly Cost Projection

**Current Optimized Cost:**
```
Original: $1,157/month
After optimizations: $721/month
Savings: 38% reduction
```

**With all planned optimizations:**
```
Current: $1,157/month
Fully optimized: $260/month (AKS + all optimizations)
Savings: 78% reduction
```

### Cost Per Tenant Analysis

**With 20 active tenants:**
```
Monthly infrastructure: $721
Cost per tenant: $36/month

Revenue per tenant: $200/month
Gross margin: 82%
```

**At 50 tenants (no additional infrastructure):**
```
Monthly infrastructure: $721
Cost per tenant: $14.42/month

Revenue per tenant: $200/month
Gross margin: 93%
```

### Cost Monitoring & Alerts

```bash
# Set budget alerts
az consumption budget create \
    --resource-group calibra-prod-rg \
    --budget-name calibra-monthly-budget \
    --amount 800 \
    --time-grain Monthly \
    --start-date 2024-11-01 \
    --category Cost

# Add alert at 80% threshold
az monitor action-group create \
    --name calibra-cost-alerts \
    --resource-group calibra-prod-rg \
    --short-name CostAlert \
    --email-receiver \
        name=admin \
        email-address=admin@calibra.com

# Query cost by resource
az consumption usage list \
    --start-date 2024-10-01 \
    --end-date 2024-10-31 \
    --resource-group calibra-prod-rg \
    --output table
```

---

## Performance Benchmarks & Load Testing

### Test Environment

- **Tool:** Apache Bench (ab), Locust
- **Load:** 1000 concurrent users, 10,000 requests
- **Duration:** 5-minute sustained load
- **Network:** Testing from Azure East US (same region)

### Benchmark Results

#### API Endpoint Performance

| Endpoint | RPS | Avg Response | p95 | p99 | Error Rate |
|----------|-----|--------------|-----|-----|------------|
| `GET /api/srfs/` | 287 | 135ms | 380ms | 520ms | 0% |
| `GET /api/srfs/{id}/` | 412 | 98ms | 210ms | 340ms | 0% |
| `POST /api/srfs/` | 156 | 245ms | 520ms | 780ms | 0.2% |
| `GET /api/observations/` | 320 | 110ms | 290ms | 410ms | 0% |
| `POST /api/observations/` | 178 | 198ms | 450ms | 650ms | 0.1% |
| `POST /api/certificates/generate/` | 45 | 4200ms | 5800ms | 7200ms | 0.5% |

#### Database Query Performance

```bash
# Tested with 100K SRFs, 500K observations across 20 tenants
```

| Query Type | Before Optimization | After Optimization | Improvement |
|------------|--------------------|--------------------|-------------|
| List SRFs (50 rows) | 3,200ms | 185ms | 94% faster |
| SRF Detail (with relations) | 890ms | 45ms | 95% faster |
| Dashboard aggregations | 8,500ms | 420ms | 95% faster |
| Search across tenants | 12,000ms | 680ms | 94% faster |
| Observation create | 320ms | 120ms | 62% faster |

#### PDF Generation Throughput

```bash
# Celery workers: 10 concurrent workers
# Test: Generate 500 certificates simultaneously
```

| Metric | Value |
|--------|-------|
| **Average generation time** | 4.2s |
| **p95 generation time** | 5.8s |
| **p99 generation time** | 7.3s |
| **Throughput** | 142 PDFs/minute |
| **Queue wait time** | <500ms |
| **Success rate** | 99.6% |

#### Multi-Tenant Scaling Test

```python
# Simulate 20 tenants with varying load
# Total: 1000 concurrent users distributed across tenants
```

| Tenant Size | Concurrent Users | Avg Response Time | Database Connections |
|-------------|------------------|-------------------|----------------------|
| Small (1-5 users) | 5 | 95ms | 3-4 |
| Medium (10-50 users) | 30 | 140ms | 12-15 |
| Large (100+ users) | 200 | 280ms | 45-50 |
| **Total** | **1000** | **220ms avg** | **165 / 200 max** |

**Result:** No tenant experienced degradation due to noisy neighbors âœ…

#### Cache Hit Rate Analysis

```bash
# Measured over 24-hour period
```

| Cache Type | Requests | Hit Rate | Avg Latency (hit) | Avg Latency (miss) |
|------------|----------|----------|-------------------|---------------------|
| Session cache | 1.2M | 98.5% | 1ms | 45ms |
| Query results | 450K | 87% | 2ms | 120ms |
| API responses | 280K | 72% | 3ms | 180ms |
| Static config | 95K | 99.8% | <1ms | 25ms |

**Overall cache effectiveness:** Reduced database load by ~65%

#### Stress Test - Peak Load

```bash
# Simulate Black Friday scenario (5x normal load)
# 5000 concurrent users, sustained for 30 minutes
```

| Metric | Normal Load | 5x Peak Load | Status |
|--------|-------------|--------------|--------|
| Requests/sec | 250 | 1,125 | âœ… Handled |
| Avg response time | 135ms | 480ms | âœ… Acceptable |
| Error rate | 0.1% | 2.3% | âš ï¸ Elevated |
| Database CPU | 35% | 89% | âš ï¸ High |
| App Service CPU | 45% | 92% | âš ï¸ High |
| Auto-scale triggered | No | Yes (10 instances) | âœ… Working |

**Verdict:** System handled 5x load but database became bottleneck. Recommendation: Implement read replicas.

#### Load Testing Scripts

**Locust test for multi-tenant simulation:**

```python
# locustfile.py
from locust import HttpUser, task, between
import random

class CalibraTenantUser(HttpUser):
    wait_time = between(1, 3)

    tenants = ['acme', 'techco', 'labx', 'precision', 'instruments']

    def on_start(self):
        self.tenant = random.choice(self.tenants)
        # Login to get JWT
        response = self.client.post("/api/auth/login/", json={
            "username": f"user@{self.tenant}.com",
            "password": "test123"
        })
        self.token = response.json()['access_token']
        self.headers = {"Authorization": f"Bearer {self.token}"}

    @task(3)
    def list_srfs(self):
        self.client.get(
            "/api/srfs/",
            headers=self.headers,
            name=f"[{self.tenant}] List SRFs"
        )

    @task(2)
    def get_srf_detail(self):
        srf_id = random.randint(1, 1000)
        self.client.get(
            f"/api/srfs/{srf_id}/",
            headers=self.headers,
            name=f"[{self.tenant}] SRF Detail"
        )

    @task(1)
    def create_observation(self):
        self.client.post(
            "/api/observations/",
            json={
                "srf_id": random.randint(1, 100),
                "measurement_value": random.uniform(20.0, 25.0),
                "notes": "Load test observation"
            },
            headers=self.headers,
            name=f"[{self.tenant}] Create Observation"
        )

# Run test
# locust -f locustfile.py --host=https://calibra-prod.azurewebsites.net --users 1000 --spawn-rate 50
```

### Performance Optimization Techniques Applied

1. **Database Connection Pooling**
   - PgBouncer with 200 max connections
   - Connection reuse (CONN_MAX_AGE=600)
   - Result: 60% reduction in connection overhead

2. **Query Optimization**
   - select_related() for foreign keys
   - prefetch_related() for reverse relations
   - Database indexes on frequently queried fields
   - Result: 94% reduction in query time

3. **Caching Strategy**
   - Redis for session storage (99.8% hit rate)
   - Query result caching (87% hit rate)
   - Template fragment caching
   - Result: 65% reduction in database load

4. **Async Task Processing**
   - Celery for PDF generation (142 PDFs/min)
   - Task priority queues
   - Result: Zero timeout errors

5. **Auto-scaling**
   - CPU-based scaling (75% threshold)
   - 2-10 instance range
   - Result: Handled 5x peak load

---

## Interview Preparation

### Key Talking Points

**Opening Statement:**
> "I architected and deployed Calibra, a multi-tenant SaaS platform on Azure that processes 10,000+ calibration requests annually. The platform demonstrates my expertise in cloud-native architecture, database optimization, and production operations at scale."

### Common Interview Questions & Scripted Answers

**Q1: Walk me through the architecture of Calibra.**

**A:** Calibra is a multi-tenant Django application deployed on Azure App Service with PostgreSQL schema-based isolation. Here's the architecture:

*[Draw architecture diagram on whiteboard]*

- **Web tier:** Azure App Service with auto-scaling (2-10 instances) running Django + Gunicorn
- **Data tier:** Azure PostgreSQL Flexible Server using django-tenants for schema isolationâ€”each client gets their own PostgreSQL schema ensuring zero data leakage
- **Cache tier:** Redis Premium for session storage, Celery broker, and query result caching
- **Storage:** Azure Blob Storage for PDF certificates (50GB+ with lifecycle management)
- **Workers:** Separate App Service instances running 10 concurrent Celery workers for async PDF generation
- **Monitoring:** Application Insights with custom telemetry and distributed tracing

The key innovation is the multi-tenant architecture. Instead of separate databases per client, we use PostgreSQL schemasâ€”think of it like virtual databases within one physical database. Django-tenants middleware inspects the incoming subdomain (e.g., acme.calibra.com), sets the database search_path to the correct schema, and all subsequent queries are automatically isolated. This gives us complete data isolation with operational simplicity.

---

**Q2: How did you ensure data isolation between tenants?**

**A:** Multi-tenant data isolation was our #1 security requirement. I implemented a defense-in-depth strategy:

**Layer 1 - Database Level:**
```python
# PostgreSQL schema-based isolation
# Each tenant gets their own schema: client_acme, client_techco, etc.
# Middleware automatically sets: SET search_path TO "client_acme"
# All queries are now scoped to that schema
```

**Layer 2 - Application Level:**
```python
# Custom decorator for critical operations
def ensure_tenant_context(func):
    def wrapper(*args, **kwargs):
        if connection.tenant is None:
            raise ValueError("No tenant context!")
        return func(*args, **kwargs)
    return wrapper
```

**Layer 3 - Testing:**
- Created automated tests that attempt cross-tenant queries
- If test successfully retrieves another tenant's data = test FAILS
- This caught 3 bugs during development

**Layer 4 - Auditing:**
- All queries logged with tenant ID
- Daily audits checking for cross-tenant access patterns
- Alert if any query touches multiple schemas

**Result:** Zero data leakage incidents in 8 months of production operation. Passed SOC 2 Type II audit.

---

**Q3: Tell me about a challenging performance problem you solved.**

**A:** When we launched Calibra, the dashboard was taking 8-10 seconds to loadâ€”completely unacceptable. The issue was N+1 queries.

**Problem:**
```python
# Bad code (generated 500+ queries)
srfs = ServiceRequirement.objects.all()
for srf in srfs:
    print(srf.equipment.name)  # NEW QUERY
    print(srf.technician.name)  # NEW QUERY
    print(srf.observations.count())  # NEW QUERY
```

**Diagnosis:**
I added Django Debug Toolbar and saw we were executing 500+ database queries for 50 rows. Classic N+1 problem.

**Solution:**
```python
# Optimized (5 queries total)
srfs = (ServiceRequirement.objects
    .select_related('equipment', 'technician', 'customer')  # JOIN
    .prefetch_related('observations__measurements')  # Batch fetch
    .only('id', 'date', 'status')  # Defer large fields
    .order_by('-created_date'))
```

**Additional optimizations:**
1. Added database indexes on foreign keys and date fields
2. Implemented Redis caching with 5-minute TTL for dashboard data
3. Used pagination (50 results per page)

**Result:**
- 8,500ms â†’ 420ms (95% improvement)
- Database CPU dropped from 85% to 35%
- Could now support 1000+ concurrent users

**Lesson learned:** Always use django-debug-toolbar in development. Always. The 5 minutes to install it saves hours of debugging.

---

**Q4: How did you handle database migrations with zero downtime?**

**A:** Database migrations in a multi-tenant system are complex because you can't afford downtime, and you have 20 schemas to migrate.

**My blue-green migration strategy:**

```python
class TenantMigrationOrchestrator:
    def migrate_in_batches(self, migration_name):
        # Step 1: Migrate low-traffic tenants first (canaries)
        canary_tenants = ['client_test', 'client_demo']
        for tenant in canary_tenants:
            self.migrate_tenant(tenant, migration_name)
            self.verify_migration(tenant)

        # Step 2: Monitor for 1 hour
        time.sleep(3600)

        # Step 3: If successful, migrate remaining tenants in batches
        remaining_tenants = self.get_production_tenants()
        for batch in chunks(remaining_tenants, 3):
            for tenant in batch:
                with transaction.atomic():
                    self.migrate_tenant(tenant, migration_name)
                    if not self.verify_migration(tenant):
                        transaction.rollback()
                        alert_admin(f"Migration failed for {tenant}")
                        return False

        return True
```

**Key principles:**
1. **Canary deployments** - Test on low-risk tenants first
2. **Backwards-compatible schemas** - New code works with old schema during migration window
3. **Per-tenant transactions** - If one tenant fails, others aren't affected
4. **Automated rollback** - If verification fails, instantly rollback that tenant
5. **Monitoring** - Watch error rates, response times during migration

**Real example:**
When we added the `certificate_status` column, I wrote an idempotent migration:
```sql
DO $$
BEGIN
    IF NOT EXISTS (SELECT 1 FROM information_schema.columns
                   WHERE table_name='servicerequirement'
                   AND column_name='certificate_status') THEN
        ALTER TABLE servicerequirement ADD COLUMN certificate_status VARCHAR(50);
    END IF;
END $$;
```

This way, if the migration partially failed, we could re-run it safely.

**Result:** Zero downtime deployments for all 15 production migrations.

---

**Q5: How did you optimize PDF generation from 30s to 5s?**

**A:** PDF generation was our biggest bottleneckâ€”calibration certificates are complex documents with graphs, tables, and signatures.

**Original problem:**
- Synchronous PDF generation in the web request
- 30 seconds per PDF
- Timeouts, frustrated users, server overload

**Solution - 3-phase optimization:**

**Phase 1: Move to async (Celery)**
```python
# Before: Synchronous (blocking)
def generate_certificate(request, srf_id):
    pdf = create_pdf(srf_id)  # Blocks for 30s
    return FileResponse(pdf)

# After: Async
@api_view(['POST'])
def generate_certificate(request, srf_id):
    task = generate_pdf_task.delay(srf_id)
    return Response({"job_id": task.id, "status": "processing"})

# Worker processes in background
@shared_task
def generate_pdf_task(srf_id):
    pdf = create_pdf(srf_id)
    upload_to_blob(pdf)
    return pdf_url
```
**Result:** API now responds in <100ms, PDF generates in background

**Phase 2: Optimize PDF generation itself**
```python
# Pre-compile templates (not on every request)
template_cache = {}

def get_template(name):
    if name not in template_cache:
        template_cache[name] = Template(open(name).read())
    return template_cache[name]

# Pre-fetch all data in ONE query
srf = (ServiceRequirement.objects
       .select_related('equipment', 'customer', 'technician')
       .prefetch_related('observations__measurements', 'attachments')
       .get(id=srf_id))

# Use optimized PDF library
from weasyprint import HTML
pdf = HTML(string=html).write_pdf()
```
**Result:** 30s â†’ 8s

**Phase 3: Caching & workers**
```python
# Cache generated PDFs
cache_key = f"pdf_{srf_id}_{srf.last_modified}"
cached = cache.get(cache_key)
if cached:
    return cached  # <50ms

# Scale workers
# 10 concurrent Celery workers = 10 PDFs simultaneously
# Throughput: 142 PDFs/minute
```
**Result:** 8s â†’ 5s, with 95% cache hit rate

**Final metrics:**
- Average: 5s (or <50ms from cache)
- Throughput: 142 PDFs/minute
- 500+ PDFs/day with zero timeouts

**Lesson:** Async processing is essential at scale. Never block web requests with heavy computation.

---

**Q6: What would you do differently if you rebuilt Calibra today?**

**A:** Great question. Here's what I'd change:

**1. Kubernetes instead of App Service**
- Better resource utilization (current: 45% CPU average = wasted capacity)
- Multi-region deployment with traffic management
- Cost savings: ~35% reduction ($400/month)

**2. Read Replicas for PostgreSQL**
- Our read:write ratio is 80:20
- Read replicas would offload dashboard queries
- Result: Lower latency, higher throughput

**3. Event-Driven Architecture**
- Currently using Django signalsâ€”works, but couples components
- Would use Azure Event Grid + Event Hubs
- Example: When SRF status changes, emit event â†’ trigger PDF generation, send email, update dashboard
- Benefits: Loose coupling, better scalability, audit trail

**4. Implement observability from day 1**
- We added Application Insights laterâ€”wish we had structured logging, distributed tracing from start
- Would use OpenTelemetry for vendor-neutral observability

**5. Infrastructure as Code (Terraform) from day 1**
- We manually created resources initially, then backfilled Terraform
- Caused drift between environments
- Would use Terraform + automated testing for infrastructure changes

**However, what I'd keep:**
- âœ… Multi-tenant architecture (schema-based)
- âœ… Event-sourcing for audit trail (SRFRecords model)
- âœ… Celery for async processing
- âœ… Comprehensive testing (87% coverage)

**The key lesson:** Start with the right foundation (IaC, observability, CI/CD). It's much harder to retrofit than to build in from the start.

---

## Lessons Learned & Best Practices

### 1. Multi-Tenancy is Complex - Plan Early
- Schema-based isolation is powerful but requires careful query construction
- Tenant middleware must be bulletproof - wrong tenant = data breach
- Migrations need tenant-aware scripts

### 2. Event Sourcing Saves Lives
- Immutable records prevented data loss during concurrent edits
- Audit trail satisfied regulatory requirements
- Debugging production issues became trivial

### 3. Async is Non-Negotiable at Scale
- Celery for PDF generation freed up web workers
- Redis as broker handled 10K+ tasks/day
- Webhook callbacks improved UX over polling

### 4. Observability from Day 1
- Azure App Insights caught issues before users reported them
- Custom metrics helped optimize tenant resource usage
- Distributed tracing identified performance bottlenecks

### 5. IaC Enables Confidence
- Terraform configurations version-controlled infrastructure
- Staging environment identical to production
- Disaster recovery tested monthly with Terraform recreate

---

## Future Roadmap

1. **Kubernetes Migration**
   Move from Azure App Service to AKS for better resource utilization and multi-region deployment

2. **ML-Powered Calibration Predictions**
   Use historical data to predict equipment failure and recommend preventive calibration

3. **Microservices Architecture**
   Split monolith into:
   - SRF Management Service
   - PDF Generation Service
   - Analytics Service
   - Notification Service

4. **GraphQL API**
   Provide flexible querying for mobile apps and integrations

5. **Real-time Collaboration**
   WebSocket-based live updates when multiple users edit same calibration

---

## Conclusion

Calibra demonstrates end-to-end ownership of a production SaaS platform from architecture through deployment and operations. The project required balancing complex business requirements with technical constraints, handling scale, ensuring data integrity, and maintaining high availability.

**Key Takeaways:**
- Multi-tenant architecture with complete data isolation
- Event-sourced state management for auditability
- Async processing for performance at scale
- Full DevOps lifecycle including IaC and monitoring
- Production Azure deployment with 99.9% uptime

This project showcases the ability to build, deploy, and operate enterprise-grade platforms that handle critical business workflows at scale.

---

**Technologies Used:**
Django 4.2, Django REST Framework, PostgreSQL, Redis, Celery, Docker, Azure App Service, Azure Blob Storage, Azure Application Insights, Terraform, GitLab CI/CD, JWT, Multi-tenancy (django-tenants)
